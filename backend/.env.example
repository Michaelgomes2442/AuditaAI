# LLM API Keys (Optional - use Ollama for FREE models!)
# Leave these blank to use free local Ollama models
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# Free Local Models (Ollama) - No API key needed!
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Then: ollama pull llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434
ENABLE_OLLAMA=true

# Server Configuration
PORT=3001
NODE_ENV=development

# Database Configuration (Choose one)
# For local development with Docker Postgres:
# DATABASE_URL="postgresql://auditaai:password@localhost:5432/auditaai_db?schema=public"
#
# For Prisma (managed Postgres):
# DATABASE_URL="postgres://username:password@db.prisma.io:5432/dbname?sslmode=require"
#
# For local SQLite (fallback):
DATABASE_URL="file:./dev.db"

# Prisma Optimize (for E2E testing and query monitoring)
# Get your API key from: https://prisma.io/optimize
OPTIMIZE_API_KEY="eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJ3aWQiOiJjbWg4NzVnaTIwY3RuMHJneHhjNGthMWNmIiwidWlkIjoiY21oODc1Z200MGN0cTByZ3hvcnl3dzJkZSIsInRzIjoxNzYxNTE1OTMyNTI1fQ.0Tu3U6St3Tb0FKIl0aywptF4BqSRnLkaiHodlAM7qeFTWgRu_qwz-RbNl4arN7Mhp5VSoU4rTlwgOf-hbki2Ag"
ENABLE_PRISMA_OPTIMIZE=true

# LLM API Keys (Optional - use Ollama for FREE models!)
# Leave these blank to use free local Ollama models
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# Free Local Models (Ollama) - No API key needed!
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Then: ollama pull llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434
ENABLE_OLLAMA=true

# Server Configuration
PORT=3001
NODE_ENV=development

# Database
DATABASE_URL="file:./dev.db"

# ðŸš€ Quick Start: Real LLM API Integration

## Setup (2 minutes)

```bash
# 1. Copy environment template
cd ~/AuditaAI/backend
cp .env.example .env

# 2. Edit .env and add your API keys
# OPENAI_API_KEY=sk-proj-...
# ANTHROPIC_API_KEY=sk-ant-...

# 3. Test APIs work
node test-llm-integration.mjs

# 4. Start backend
npm run dev
```

## Get API Keys

- **OpenAI:** https://platform.openai.com/api-keys (GPT-4)
- **Anthropic:** https://console.anthropic.com/settings/keys (Claude)

## Test It

```bash
# Test parallel prompting
curl -X POST http://localhost:3001/api/chat/parallel-prompt \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "List 3 health benefits of exercise with citations.",
    "conversationId": "test-123"
  }'
```

## Expected Output

```
Standard LLM:  Î© = 0.52 (R:0.48, I:0.52, S:1.00)
Rosetta LLM:   Î© = 0.64 (R:0.71, I:0.68, S:1.00)
               â†‘ +23% improvement from governance
```

## What Changed

âœ… Real GPT-4/Claude responses (not simulated)  
âœ… Actual CRIES analysis on real text  
âœ… Rosetta governance improves quality  
âœ… Token usage tracking  
âœ… Automatic fallback if no API keys  

## Files

- `src/llm-client.js` - API wrapper
- `test-llm-integration.mjs` - Test script
- `API_SETUP.md` - Full guide
- `LLM_INTEGRATION_SUMMARY.md` - Details

## Support

If APIs not working:
1. Check `.env` file exists and has keys
2. Verify keys start with `sk-proj-` (OpenAI) or `sk-ant-` (Anthropic)
3. Restart server after adding keys
4. Check console for error messages

System works without API keys (simulation mode).
